{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import allel\n",
    "import zarr\n",
    "import argparse\n",
    "import re\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the vcf location from the command line\n",
    "parser = argparse.ArgumentParser(description='Wrapper to compute dxy with scikit-allel for simulated data')\n",
    "parser.add_argument('--vcf', type=str, nargs='?', help='Path to the input VCF', required=True)\n",
    "#args = parser.parse_args()\n",
    "\n",
    "# test value\n",
    "#args = parser.parse_args('--vcf ../../simulating-test-data/data/simulated_missing_sites/100/pi_sim_Ne=1.0e+06_mu=1e-08_samples=100_sites=10000_0_invar.missing_100.vcf'.split())\n",
    "args = parser.parse_args()\n",
    "\n",
    "# parse the arguments\n",
    "# chromosome is always '1' in our simulated data\n",
    "chromosome = '1'\n",
    "vcf_path = args.vcf\n",
    "zarr_path = 'data/zarr/' + re.sub('.*/|.vcf.gz', '', vcf_path) + '.zarr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vcf_to_zarr] 100 rows in 0.01s; chunk in 0.01s (8254 rows/s)\n",
      "[vcf_to_zarr] all done (1789 rows/s)\n"
     ]
    }
   ],
   "source": [
    "# generate the zarr array \n",
    "allel.vcf_to_zarr(vcf_path, zarr_path, group=chromosome, fields='*', log=sys.stdout, overwrite=True)\n",
    "callset = zarr.open_group(zarr_path, mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of samples from the callset\n",
    "samples = callset[chromosome + '/samples'][:]\n",
    "samples_list = list(samples)\n",
    "#print('VCF samples:', samples_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# window size\n",
    "# this is fixed (1-10000) in our simulated data\n",
    "window_start = 1\n",
    "window_end = 10000\n",
    "window_range = list(range(window_start, window_end))\n",
    "\n",
    "# the genotype calls\n",
    "# recode the gt matrix as a Dask array (saves memory)\n",
    "gt_dask = allel.GenotypeDaskArray(callset[chromosome + '/calldata/GT'])\n",
    "gt_array = allel.GenotypeArray(gt_dask).to_packed()\n",
    "gt_array = allel.GenotypeArray.from_packed(gt_array)\n",
    "\n",
    "pos_array = allel.SortedIndex(callset[chromosome + '/variants/POS'])\n",
    "loc_region = pos_array.locate_range(window_start, window_end)\n",
    "gt_region = gt_array[loc_region]\n",
    "\n",
    "# 50 = number of samples\n",
    "# gt_pop = gt_region.take(range(0,50), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # create pi name via the prefix\n",
    "sci_pi_file = \"data/dxy_out/allel_\" + re.sub('.*/|.vcf*', '', vcf_path) +\"_dxy.txt\"\n",
    "outfile = open(sci_pi_file, 'w')\n",
    "outfile.write(\"filename\" + \"\\t\" + \"chromosome\" + \"\\t\" + \"window_pos_1\" + \"\\t\" + \"window_pos_2\" + \"\\t\" + \"sk_allel_avg_dxy\" + \"\\t\" + \"sk_allel_no_sites\" + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute dxy (for the whole region)\n",
    "# the idea here is to arbitrary divide the population into two \"populations\"\n",
    "# the expected value of dxy = pi (of the total sample) in this case \n",
    "\n",
    "hap_p1 = gt_region.subset(sel0=range(window_start,len(gt_region)), sel1=range(0,24)).to_haplotypes() \n",
    "hap_p2 = gt_region.subset(sel0=range(window_start,len(gt_region)), sel1=range(25,49)).to_haplotypes() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac1 = hap_p1.count_alleles()\n",
    "ac2 = hap_p2.count_alleles()\n",
    "dxy_est = allel.sequence_divergence(window_range, ac1, ac2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write to file\n",
    "outfile.write(re.sub('.*/|.vcf.gz', '', vcf_path) + \"\\t\" + str(chromosome) + \"\\t\" + str(window_start) + \"\\t\" + str(window_end) + \"\\t\" + str(dxy_est) + \"\\t\" + len(gt_region) + \"\\n\")\n",
    "outfile.close()\n",
    "\n",
    "# nuke zarr folder\n",
    "os.system(\"rm -r \" + zarr_path)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "pixy",
   "language": "python",
   "name": "pixy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
